{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vgg8UzrhCnq"
      },
      "source": [
        "### Applico un algoritmo di rete neurale densa (Dense Neural Network) a un dataset di classificazione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "e4nk4lCWhCnr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "sns.set_theme()\n",
        "\n",
        "random_state = 42"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/dataset_titanic.csv')\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ddbs-6Vu0kNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_titanic_dataset(df_train, df_test):\n",
        "    df_train = df_train.copy(deep=True)\n",
        "    df_test = df_test.copy(deep=True)\n",
        "\n",
        "    df_X_train_preprocessed = pd.DataFrame(index=df_train.index)\n",
        "    df_X_test_preprocessed = pd.DataFrame(index=df_test.index)\n",
        "\n",
        "    series_y_train = pd.Series(index=df_train.index, data=df_train['Survived'])\n",
        "    series_y_test = pd.Series(index=df_test.index, data=df_test['Survived'])\n",
        "\n",
        "    # Fill nan values for column 'Embarked'\n",
        "    embarked_mode = df_train['Embarked'].mode()[0]\n",
        "    df_train['Embarked'] = df_train['Embarked'].fillna(embarked_mode)\n",
        "    df_test['Embarked'] = df_test['Embarked'].fillna(embarked_mode)\n",
        "\n",
        "    # Fill nan values for column 'Age'\n",
        "    age_median = df_train['Age'].median()\n",
        "    df_train['Age'] = df_train['Age'].fillna(age_median)\n",
        "    df_test['Age'] = df_test['Age'].fillna(age_median)\n",
        "\n",
        "    # Standardization for numerical features\n",
        "    features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "    ss = StandardScaler()\n",
        "    X_train_std = ss.fit_transform(df_train[features])\n",
        "    X_test_std = ss.transform(df_test[features])\n",
        "    df_X_train_preprocessed[features] = X_train_std\n",
        "    df_X_test_preprocessed[features] = X_test_std\n",
        "\n",
        "    # One-hot-encoding for categorical features\n",
        "    features = ['Sex', 'Embarked']\n",
        "    ohe = OneHotEncoder(drop='first', sparse_output=False,handle_unknown='ignore')\n",
        "    X_train_ohe = ohe.fit_transform(df_train[features])\n",
        "    X_test_ohe = ohe.transform(df_test[features])\n",
        "    features_names_out = ohe.get_feature_names_out()\n",
        "    df_X_train_preprocessed[features_names_out] = X_train_ohe\n",
        "    df_X_test_preprocessed[features_names_out] = X_test_ohe\n",
        "\n",
        "    return df_X_train_preprocessed, df_X_test_preprocessed, series_y_train, series_y_test\n",
        "\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test, show_confusion_matrix=False):\n",
        "  train_probs = model.predict(X_train).ravel()\n",
        "  test_probs = model.predict(X_test).ravel()\n",
        "\n",
        "  y_train_pred = (train_probs > 0.5).astype(int)\n",
        "  y_test_pred = (test_probs > 0.5).astype(int)\n",
        "\n",
        "  acc_train = accuracy_score(y_train, y_train_pred)\n",
        "  acc_test = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "  print(f\"accuracy train: {acc_train:.3f}\")\n",
        "  print(f\"accuracy test: {acc_test:.3f}\")\n",
        "\n",
        "  cf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "  if show_confusion_matrix:\n",
        "    ax = sns.heatmap(cf_matrix_test, annot=True, fmt='d')\n",
        "    ax.set_title('Confusion matrix on test set')\n",
        "    ax.set_xlabel('Predicted values')\n",
        "    ax.set_ylabel('True values')\n",
        "    plt.show()\n",
        "\n",
        "  return acc_train, acc_test, cf_matrix_test"
      ],
      "metadata": {
        "id": "x-AIuFWx0ais"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = train_test_split(df, test_size=.2, random_state=random_state)\n",
        "\n",
        "df_X_train_preprocessed, df_X_test_preprocessed, series_y_train, series_y_test = preprocess_titanic_dataset(df_train, df_test)\n",
        "\n",
        "X_train = df_X_train_preprocessed.values\n",
        "\n",
        "X_test = df_X_test_preprocessed.values\n",
        "\n",
        "y_train = series_y_train.values\n",
        "\n",
        "y_test = series_y_test.values"
      ],
      "metadata": {
        "id": "TFaaKhGy7IU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Add a Dense (fully connected) layer with 64 units(neurons) and ReLU activation\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(df_X_train_preprocessed.shape[1],)))\n",
        "\n",
        "# Add another layer\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "# Add a final output layer with 1 unit for binary classification\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6LFuNHY15fHD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model by specifying the optimizer, loss function, and metrics to\n",
        "# track\n",
        "model.compile(\n",
        "    optimizer='adam',               # Adam optimizer for adaptive learning rate adjustments\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']            # Metric to track: accuracy of predictions\n",
        ")"
      ],
      "metadata": {
        "id": "-7yWpMFS6Rg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 25\n",
        "\n",
        "# Train the model on the training data with specified parameters\n",
        "history = model.fit(\n",
        "    X_train,                # Training input data\n",
        "    y_train,                # Training labels (target values)\n",
        "    epochs=n_epochs,               # Number of times the entire dataset will be iterated over\n",
        "    batch_size=64,          # Number of samples per gradient update\n",
        "    validation_split=0.2    # Fraction of training data (20%) to use as validation data\n",
        ")"
      ],
      "metadata": {
        "id": "mQucjC-I6zbX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_training_history = pd.DataFrame(history.history, index=range(1, n_epochs+1))\n",
        "\n",
        "df_training_history.index.name = 'epoch'\n",
        "\n",
        "df_training_history"
      ],
      "metadata": {
        "collapsed": true,
        "id": "685raz4Im4-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 1, figsize=(10, 7))\n",
        "\n",
        "sns.lineplot(x=df_training_history.index, y=df_training_history['loss'], ax=axs[0], label='Loss training')\n",
        "\n",
        "sns.lineplot(x=df_training_history.index, y=df_training_history['val_loss'], ax=axs[0], label='Loss validation')\n",
        "\n",
        "sns.lineplot(x=df_training_history.index, y=df_training_history['accuracy'], ax=axs[1], label='Accuracy training')\n",
        "\n",
        "sns.lineplot(x=df_training_history.index, y=df_training_history['val_accuracy'], ax=axs[1], label='Accuracy validation')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F1rRmpSfnjA2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, X_train, y_train, X_test, y_test, show_confusion_matrix=True)"
      ],
      "metadata": {
        "id": "E0f83HMJrz_F",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}